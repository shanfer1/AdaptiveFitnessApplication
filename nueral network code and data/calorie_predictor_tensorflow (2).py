# -*- coding: utf-8 -*-
"""Calorie Predictor Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ji4Q-jN8mh3FwqQErheswfh1qdQhC9cr
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('transformed__excercise_dataset.csv')
df.head(10)

# Separate the features and the target variable
X = df.drop(['ID','Calories Burn','Exercise','Weather Conditions'], axis=1)
y = df['Calories Burn']
X
# import numpy as np
# bins = [0, 119, 144, np.inf]
# labels_HeartRate = ['Low', 'Normal', 'High']
# df['Heart Rate Category'] = pd.cut(df['Heart Rate'], bins=bins, labels=labels_HeartRate)

# print(df[['Heart Rate', 'Heart Rate Category']])

# bins = [0, 40, 50, np.inf]
# labels_Duration= ['Low', 'Average', 'High']
# df['Duration Category'] = pd.cut(df['Duration'], bins=bins, labels=labels_Duration)

# print(df[['Duration', 'Duration Category']])

# # One-hot encode the 'Heart Rate Category'
# one_hot_encoder = OneHotEncoder(sparse=False)  # drop='first' to avoid dummy variable trap
# heart_rate_category_encoded = one_hot_encoder.fit_transform(df[['Heart Rate Category']])
# heart_rate_category_df = pd.DataFrame(heart_rate_category_encoded, columns=one_hot_encoder.get_feature_names_out())
# print(heart_rate_category_df)

# # One-hot encode the 'Duration Category'
# one_hot_encoder = OneHotEncoder(sparse=False)  # drop='first' to avoid dummy variable trap
# duration_category_encoded = one_hot_encoder.fit_transform(df[['Duration Category']])
# duration_category_df = pd.DataFrame(duration_category_encoded, columns=one_hot_encoder.get_feature_names_out())
# print(duration_category_df)

# Create a new DataFrame that includes the target to compute correlation
df_with_target = X.copy()
df_with_target['Calories Burn'] = y

df_with_target['Intensity_Duration'] = df_with_target['Exercise Intensity']*df_with_target['Duration']
print(df_with_target.columns)

# for category in labels_Duration:
#     interaction_term_name = f'Intensity_Duration_{category}_Interaction'
#     df_with_target[interaction_term_name] = df_with_target[f'Duration Category_{category}'] * df_with_target['Exercise Intensity']

# df_with_target['HR_Duration_Ratio'] = df_with_target['Heart Rate'] / df_with_target['Duration']
# df_with_target['Intensity_Duration_Product'] = df_with_target['Exercise Intensity'] * df_with_target['Duration']
# df_with_target['Weighted_Heart_Rate'] = df_with_target['Heart Rate'] * df_with_target['Exercise Intensity']

# dropcols=['Heart Rate','Duration','Exercise Intensity']


# for category in labels_Duration:
#   dropcols.append(f'Duration Category_{category}')
# print(dropcols)

# df_with_target = df_with_target.drop(columns=dropcols)


# print(df_with_target.columns)

correlation_matrix = df_with_target.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix with Calories Burned')
plt.show()

# numerical_cols = [
#     'Age', 'Actual Weight', 'Dream Weight', 'BMI',
#     'HR_Duration_Ratio', 'Intensity_Duration_Product', 'Weighted_Heart_Rate'
# ]

# categorical_cols = [
#     'Gender', 'Heart Rate Category_High', 'Heart Rate Category_Low', 'Heart Rate Category_Normal'
# ]


numerical_cols = [
    'Age', 'Actual Weight','Duration', 'Dream Weight', 'BMI',
    'Intensity_Duration', 'Heart Rate','Exercise Intensity'
]

categorical_cols = [
    'Gender',
]

X = df_with_target[numerical_cols + categorical_cols]
y = df_with_target['Calories Burn']
X

numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),  # Replace missing values with the mean
    ('scaler', StandardScaler())                 # Standardize numerical variables
])

# Pipeline for categorical features
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Preprocessor for column transformation
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ]
)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Apply the preprocessing to the data
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

input_shape = [X_train_processed.shape[1]]

from sklearn.preprocessing import OneHotEncoder

# Assuming 'categorical_cols' contains the column name 'Gender'
categorical_cols = ['Gender']

# Create and fit the OneHotEncoder
one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
one_hot_encoder.fit(X_train[categorical_cols])

# Get the feature names from the encoder
encoded_feature_names = one_hot_encoder.get_feature_names_out(categorical_cols)
print(encoded_feature_names)

# This will print something like ['Gender_Female', 'Gender_Male']
# indicating the order of the encoding

# Assuming X_train_processed is a numpy array
feature_names = numerical_cols + list(one_hot_encoder.get_feature_names_out(categorical_cols))
processed_df = pd.DataFrame(X_train_processed, columns=feature_names)
print(processed_df.columns)

!pip install keras

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the model architecture
model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=input_shape),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)  # Output layer
])

model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train_processed, y_train, epochs=50, validation_split=0.2)

loss = model.evaluate(X_test_processed, y_test, verbose=0)

rmse = tf.sqrt(loss)

print(f"Mean Squared Error: {loss}")
print(f"Root Mean Squared Error: {rmse}")

model.save('my_model')

import tensorflow as tf

# Convert the model to the TensorFlow Lite format
converter = tf.lite.TFLiteConverter.from_saved_model('my_model')
tflite_model = converter.convert()

# Save the model
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load your dataset
df = pd.read_csv('transformed__excercise_dataset.csv')

# Define your numerical columns
numerical_cols = [
    'Age', 'Actual Weight','Duration', 'Dream Weight', 'BMI',
    'Intensity_Duration', 'Heart Rate', 'Exercise Intensity'
]

df['Intensity_Duration']=df['Duration']*df['Exercise Intensity']
# Split your data into training and testing sets
X = df[numerical_cols]
y = df['Calories Burn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Fit a StandardScaler only on the training data
scaler = StandardScaler()
scaler.fit(X_train)

# Get the mean and standard deviation for each column
means = scaler.mean_
std_devs = scaler.scale_  # Note: scale_ is standard deviation

# Create a DataFrame to hold these statistics for easy reference
scaling_stats = pd.DataFrame({'Feature': numerical_cols, 'Mean': means, 'StdDev': std_devs})
print(scaling_stats)